{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>created_at</th>\n",
       "      <th>month</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1240727808080412673</td>\n",
       "      <td>RT @chandlerriggs: here’s a deleted scene from...</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1240727808005079041</td>\n",
       "      <td>Wuhan has been in complete quarantine for over...</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1240727808340414464</td>\n",
       "      <td>RT @RedTRaccoon: You can no longer defend this...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1240727808629813248</td>\n",
       "      <td>RT @nicolebyer: Everyone in this looks sick</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1240727808617230336</td>\n",
       "      <td>RT @RealSaavedra: Good.\\n\\nIt came from China.</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tweet_id  \\\n",
       "0           0  1240727808080412673   \n",
       "1           1  1240727808005079041   \n",
       "2           2  1240727808340414464   \n",
       "3           3  1240727808629813248   \n",
       "4           4  1240727808617230336   \n",
       "\n",
       "                                                text  sentiment  \\\n",
       "0  RT @chandlerriggs: here’s a deleted scene from...   0.357143   \n",
       "1  Wuhan has been in complete quarantine for over...   0.116071   \n",
       "2  RT @RedTRaccoon: You can no longer defend this...  -0.050000   \n",
       "3        RT @nicolebyer: Everyone in this looks sick  -0.714286   \n",
       "4     RT @RealSaavedra: Good.\\n\\nIt came from China.   0.700000   \n",
       "\n",
       "            created_at  month  classes  \n",
       "0  2020-03-19 19:52:15  March        2  \n",
       "1  2020-03-19 19:52:15  March        2  \n",
       "2  2020-03-19 19:52:15  March        0  \n",
       "3  2020-03-19 19:52:15  March        0  \n",
       "4  2020-03-19 19:52:15  March        2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.read_csv('March_Tweets.csv')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4760"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['sentiment'] = pd.to_numeric(tweets['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_tweet(tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "for i in range(len(tweets)):\n",
    "    cleaned.append(clean_tweet(tweets['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT here s a deleted scene from TWD s special on corona virus'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>created_at</th>\n",
       "      <th>month</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1240727808080412673</td>\n",
       "      <td>RT here s a deleted scene from TWD s special o...</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1240727808005079041</td>\n",
       "      <td>Wuhan has been in complete quarantine for over...</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1240727808340414464</td>\n",
       "      <td>RT You can no longer defend this Make up any e...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1240727808629813248</td>\n",
       "      <td>RT Everyone in this looks sick</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1240727808617230336</td>\n",
       "      <td>RT Good It came from China</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2020-03-19 19:52:15</td>\n",
       "      <td>March</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tweet_id  \\\n",
       "0           0  1240727808080412673   \n",
       "1           1  1240727808005079041   \n",
       "2           2  1240727808340414464   \n",
       "3           3  1240727808629813248   \n",
       "4           4  1240727808617230336   \n",
       "\n",
       "                                                text  sentiment  \\\n",
       "0  RT here s a deleted scene from TWD s special o...   0.357143   \n",
       "1  Wuhan has been in complete quarantine for over...   0.116071   \n",
       "2  RT You can no longer defend this Make up any e...  -0.050000   \n",
       "3                     RT Everyone in this looks sick  -0.714286   \n",
       "4                         RT Good It came from China   0.700000   \n",
       "\n",
       "            created_at  month  classes  \n",
       "0  2020-03-19 19:52:15  March        2  \n",
       "1  2020-03-19 19:52:15  March        2  \n",
       "2  2020-03-19 19:52:15  March        0  \n",
       "3  2020-03-19 19:52:15  March        0  \n",
       "4  2020-03-19 19:52:15  March        2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>month</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.253820e+18</td>\n",
       "      <td>Fri Apr 24 23:06:47 +0000 2020</td>\n",
       "      <td>MyPOV: PSA \"There’s no scenario that anyone ca...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>April</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.253820e+18</td>\n",
       "      <td>Fri Apr 24 23:06:45 +0000 2020</td>\n",
       "      <td>RT @samvallance30: Due to #COVID19 aka #Corona...</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>April</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.253820e+18</td>\n",
       "      <td>Fri Apr 24 23:06:39 +0000 2020</td>\n",
       "      <td>Things you shouldn't have to say: Don't Ingest...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>April</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.253820e+18</td>\n",
       "      <td>Fri Apr 24 23:06:28 +0000 2020</td>\n",
       "      <td>RT @MarcGozlan: #COVID19 #coronavirus #anosmie...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>April</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.253820e+18</td>\n",
       "      <td>Fri Apr 24 23:06:27 +0000 2020</td>\n",
       "      <td>RT @jazz_jazaiya21: Due to #COVID19 aka #Coron...</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>April</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                      created_at  \\\n",
       "0  1.253820e+18  Fri Apr 24 23:06:47 +0000 2020   \n",
       "1  1.253820e+18  Fri Apr 24 23:06:45 +0000 2020   \n",
       "2  1.253820e+18  Fri Apr 24 23:06:39 +0000 2020   \n",
       "3  1.253820e+18  Fri Apr 24 23:06:28 +0000 2020   \n",
       "4  1.253820e+18  Fri Apr 24 23:06:27 +0000 2020   \n",
       "\n",
       "                                                text  sentiment  month  \\\n",
       "0  MyPOV: PSA \"There’s no scenario that anyone ca...   0.000000  April   \n",
       "1  RT @samvallance30: Due to #COVID19 aka #Corona...  -0.125000  April   \n",
       "2  Things you shouldn't have to say: Don't Ingest...   0.000000  April   \n",
       "3  RT @MarcGozlan: #COVID19 #coronavirus #anosmie...   0.333333  April   \n",
       "4  RT @jazz_jazaiya21: Due to #COVID19 aka #Coron...  -0.125000  April   \n",
       "\n",
       "   classes  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        2  \n",
       "4        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets2 = pd.read_csv('April_Tweets.csv')\n",
    "print(len(tweets2))\n",
    "tweets2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "for i in range(len(tweets2)):\n",
    "    cleaned.append(clean_tweet(tweets2['text'][i]))\n",
    "tweets2['text'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT Friends don t listen to this lunatic Injecting or drinking bleach can KILL you and UV light is known to cause cancer'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets2['text'][len(tweets2)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>month</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Sat May 02 00:59:21 +0000 2020</td>\n",
       "      <td>RT @bbcworldservice: This nine-year-old Kenyan...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>May</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Sat May 02 00:59:20 +0000 2020</td>\n",
       "      <td>RT @RightWingLawMan: Governor Gavin Newsome Ju...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Sat May 02 00:59:19 +0000 2020</td>\n",
       "      <td>RT @violetpandora: Inside The US Government's ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Sat May 02 00:59:17 +0000 2020</td>\n",
       "      <td>Still on the face shield. Production is going....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.260000e+18</td>\n",
       "      <td>Sat May 02 00:59:16 +0000 2020</td>\n",
       "      <td>RT @RepGosar: The Wuhan #coronavirus won’t sto...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                      created_at  \\\n",
       "0  1.260000e+18  Sat May 02 00:59:21 +0000 2020   \n",
       "1  1.260000e+18  Sat May 02 00:59:20 +0000 2020   \n",
       "2  1.260000e+18  Sat May 02 00:59:19 +0000 2020   \n",
       "3  1.260000e+18  Sat May 02 00:59:17 +0000 2020   \n",
       "4  1.260000e+18  Sat May 02 00:59:16 +0000 2020   \n",
       "\n",
       "                                                text  sentiment month  classes  \n",
       "0  RT @bbcworldservice: This nine-year-old Kenyan...        0.5   May        2  \n",
       "1  RT @RightWingLawMan: Governor Gavin Newsome Ju...        0.0   May        1  \n",
       "2  RT @violetpandora: Inside The US Government's ...        0.0   May        1  \n",
       "3  Still on the face shield. Production is going....        0.0   May        1  \n",
       "4  RT @RepGosar: The Wuhan #coronavirus won’t sto...        0.0   May        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets3 = pd.read_csv('May_Tweets.csv')\n",
    "tweets3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4760"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT This nine year old Kenyan inventor has come up with an ingenious way to wash his hands and reduce the spread of the'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = []\n",
    "for i in range(len(tweets3)):\n",
    "    cleaned.append(clean_tweet(tweets3['text'][i]))\n",
    "tweets3['text'] = cleaned\n",
    "tweets3['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = tweets.append(tweets2, sort=False)\n",
    "combined = combined.append(tweets3)\n",
    "#Preparing the March dataset for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12344"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For March Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = tweets['text']\n",
    "y = tweets['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1473\n",
      "X_train:\n",
      "<3332x1473 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 20716 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<1428x1473 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 8107 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 1473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7301931088853608\n",
      "--- 0.058812856674194336 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import time\n",
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For April Dataset\n",
    "X = tweets2['text']\n",
    "y = tweets2['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1141\n",
      "X_train:\n",
      "<3127x1141 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 48626 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<1341x1141 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 20322 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 1141\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9323991568233461\n",
      "--- 0.08061742782592773 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For May Dataset\n",
    "X = tweets3['text']\n",
    "y = tweets3['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 952\n",
      "X_train:\n",
      "<2181x952 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 24157 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<935x952 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 9884 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 952\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787699203723857\n",
      "--- 0.039853572845458984 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3830\n",
      "X_train:\n",
      "<8640x3830 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 99094 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<3704x3830 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 40913 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 3830\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8567845717994869\n",
      "--- 0.25736308097839355 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419882437520688\n",
      "--- 1.1838760375976562 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Decison Tree Classifier\n",
    "from sklearn import tree\n",
    "start_time = time.time()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6384700003620489\n",
      "--- 0.04133105278015137 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits\n",
    "# 90% train and 10% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4780\n",
      "X_train:\n",
      "<11109x4780 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 131509 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<1235x4780 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 14117 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 4780\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8637706381079875\n",
      "--- 0.36603856086730957 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits\n",
    "# 50% train and 50% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2800\n",
      "X_train:\n",
      "<6172x2800 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 68079 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<6172x2800 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 64156 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 2800\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827993400209726\n",
      "--- 0.15762591361999512 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits\n",
    "# 30% train and 70% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1684\n",
      "X_train:\n",
      "<3703x1684 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 37052 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<8641x1684 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 82246 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 1684\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8071377541998233\n",
      "--- 0.0697031021118164 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits for Decision Tree Classifier\n",
    "# 90% train and 10% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4780\n",
      "X_train:\n",
      "<11109x4780 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 131509 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<1235x4780 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 14117 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 4780\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8577569537408893\n",
      "--- 1.9547877311706543 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Decison Tree Classifier\n",
    "from sklearn import tree\n",
    "start_time = time.time()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits for Decision Tree Classifier\n",
    "# 50% train and 50% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2800\n",
      "X_train:\n",
      "<6172x2800 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 68079 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<6172x2800 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 64156 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 2800\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8209346028361174\n",
      "--- 0.6041150093078613 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Decison Tree Classifier\n",
    "from sklearn import tree\n",
    "start_time = time.time()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits for Decision Tree Classifier\n",
    "# 30% train and 70% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1684\n",
      "X_train:\n",
      "<3703x1684 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 37052 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<8641x1684 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 82246 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 1684\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7960251105216622\n",
      "--- 0.20143508911132812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Decison Tree Classifier\n",
    "from sklearn import tree\n",
    "start_time = time.time()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits for Random Forest Classifier\n",
    "# 90% train and 10% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4780\n",
      "X_train:\n",
      "<11109x4780 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 131509 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<1235x4780 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 14117 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 4780\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6353711140859735\n",
      "--- 0.038901567459106445 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits for Random Forest Classifier\n",
    "# 50% train and 50% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2800\n",
      "X_train:\n",
      "<6172x2800 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 68079 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<6172x2800 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 64156 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 2800\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6410962233581348\n",
      "--- 0.03585243225097656 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Different Training splits for Random Forest Classifier\n",
    "# 30% train and 70% test\n",
    "#For combined Dataset\n",
    "X = combined['text']\n",
    "y = combined['classes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1684\n",
      "X_train:\n",
      "<3703x1684 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 37052 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<8641x1684 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 82246 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 1684\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 2))\n",
    "X_train = vect.fit(X_train).transform(X_train)\n",
    "X_test = vect.transform(X_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6450748600058944\n",
      "--- 0.03390908241271973 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label=2)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
